{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8f13ff",
   "metadata": {},
   "source": [
    "## Data Class ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "215a5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "\n",
    "\n",
    "\n",
    "class Review:\n",
    "    \n",
    "    def __init__(self,text,score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score ==3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else:\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    \n",
    "    def __init__(self,reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    def get_text(self):\n",
    "        return[x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return[x.sentiment for x in self.reviews]\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)] \n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        \n",
    "    \n",
    "    \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426579f0",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc720da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './sklearn-master/data/sentiment/Books_small_10000.json'\n",
    "\n",
    "\n",
    "with open(file_name) as f:\n",
    "    \n",
    "    reviews = []\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46a83849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[45].sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538f832",
   "metadata": {},
   "source": [
    "## Prep Data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7f6f2",
   "metadata": {},
   "source": [
    "### Splitting the dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5fed935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size = 0.33, random_state = 42) \n",
    "\n",
    "training_cont = ReviewContainer(training)\n",
    "\n",
    "test_cont = ReviewContainer(test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f4db479",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cont.evenly_distribute()\n",
    "train_x = training_cont.get_text()\n",
    "train_y = training_cont.get_sentiment()\n",
    "\n",
    "test_cont.evenly_distribute()\n",
    "test_x = test_cont.get_text()\n",
    "test_y = test_cont.get_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b80fb",
   "metadata": {},
   "source": [
    "### Bag of words vectorization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2e5130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11e00b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you love owls this is a great book. There are lots of beautiful pictures of owls in action. There is wonderful information to learn and the author has tons of experience as an expert. Very happy with this!\n",
      "  (0, 8760)\t0.07421499687856961\n",
      "  (0, 3625)\t0.18050129175492904\n",
      "  (0, 8497)\t0.09806400637321677\n",
      "  (0, 2868)\t0.26455692242053824\n",
      "  (0, 416)\t0.09556743631521478\n",
      "  (0, 569)\t0.09374858732299207\n",
      "  (0, 2861)\t0.18211963703882597\n",
      "  (0, 8078)\t0.28063116262372156\n",
      "  (0, 3652)\t0.10617385773663535\n",
      "  (0, 660)\t0.10715885136834707\n",
      "  (0, 7929)\t0.04739299890952387\n",
      "  (0, 423)\t0.05013603771081082\n",
      "  (0, 4600)\t0.17600849453734507\n",
      "  (0, 8052)\t0.05152085724393126\n",
      "  (0, 4101)\t0.18741334946139915\n",
      "  (0, 8781)\t0.17327334429528585\n",
      "  (0, 205)\t0.17745025175969675\n",
      "  (0, 4034)\t0.06504419519402634\n",
      "  (0, 5868)\t0.2034875896645825\n",
      "  (0, 791)\t0.20075243942252327\n",
      "  (0, 5478)\t0.17301860941493563\n",
      "  (0, 4778)\t0.19352449196288005\n",
      "  (0, 525)\t0.09538175000727388\n",
      "  (0, 7951)\t0.20536773531112873\n",
      "  (0, 991)\t0.058249519306755024\n",
      "  (0, 3495)\t0.11394052070882581\n",
      "  (0, 4264)\t0.12906088691292822\n",
      "  (0, 7976)\t0.10629372491050777\n",
      "  (0, 5636)\t0.5612623252474431\n",
      "  (0, 4782)\t0.11335319212548052\n",
      "  (0, 8879)\t0.08720803812404053\n",
      "  (0, 3968)\t0.10136958306480391\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])\n",
    "print(train_x_vectors[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80866bb",
   "metadata": {},
   "source": [
    "## Classification ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d19bc",
   "metadata": {},
   "source": [
    "### SVM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3f5b5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe5887",
   "metadata": {},
   "source": [
    "### Decision Tree ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9d5fc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ffb54",
   "metadata": {},
   "source": [
    "### Naive Bayes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81e5719b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0].toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eeb311",
   "metadata": {},
   "source": [
    "### Logistic Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cef538a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lg = LogisticRegression()\n",
    "\n",
    "clf_lg.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_lg.predict(test_x_vectors[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f8a20",
   "metadata": {},
   "source": [
    "## Evaluation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfc33d",
   "metadata": {},
   "source": [
    "### Mean Accuracy ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee447c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6322115384615384\n",
      "0.6610576923076923\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors.toarray(), test_y))\n",
    "print(clf_lg.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade97b5a",
   "metadata": {},
   "source": [
    "### F1 score ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c954f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80582524 0.         0.80952381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steven/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y,clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "# print(f1_score(test_y,clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "# print(f1_score(test_y,clf_gnb.predict(test_x_vectors.toarray()), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "# print(f1_score(test_y,clf_lg.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eee45d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.count('NEGATIVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb5ef2",
   "metadata": {},
   "source": [
    "### Qualitative evaluation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f064723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['awesome', \"bad book do not buy\", 'horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a02df",
   "metadata": {},
   "source": [
    "### Tuning our model (GridSearch) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fa402c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.14858041, 0.1511272 , 0.15023031, 0.15259829, 0.15030336,\n",
       "        0.15245337, 0.14999604, 0.1524929 , 0.15013065, 0.152596  ]),\n",
       " 'std_fit_time': array([0.01263306, 0.00093014, 0.00107627, 0.00107753, 0.00094869,\n",
       "        0.0009749 , 0.00101457, 0.00095868, 0.00105039, 0.00107546]),\n",
       " 'mean_score_time': array([0.03127947, 0.03644471, 0.03081455, 0.03659735, 0.03082266,\n",
       "        0.03653007, 0.03081894, 0.03669171, 0.03084302, 0.03659673]),\n",
       " 'std_score_time': array([0.00035962, 0.00018968, 0.00037504, 0.00029284, 0.00026099,\n",
       "        0.00029947, 0.00034683, 0.00025071, 0.00030068, 0.00018528]),\n",
       " 'param_C': masked_array(data=[1, 1, 4, 4, 8, 8, 16, 16, 32, 32],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'kernel': 'linear'},\n",
       "  {'C': 4, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'kernel': 'linear'},\n",
       "  {'C': 8, 'kernel': 'rbf'},\n",
       "  {'C': 16, 'kernel': 'linear'},\n",
       "  {'C': 16, 'kernel': 'rbf'},\n",
       "  {'C': 32, 'kernel': 'linear'},\n",
       "  {'C': 32, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.85714286, 0.81142857, 0.81142857, 0.82857143, 0.81142857,\n",
       "        0.82857143, 0.81142857, 0.82857143, 0.81142857, 0.82857143]),\n",
       " 'split1_test_score': array([0.84      , 0.81142857, 0.81714286, 0.82285714, 0.81714286,\n",
       "        0.82285714, 0.81714286, 0.82285714, 0.81714286, 0.82285714]),\n",
       " 'split2_test_score': array([0.79310345, 0.77011494, 0.79310345, 0.75862069, 0.79310345,\n",
       "        0.75862069, 0.79310345, 0.75862069, 0.79310345, 0.75862069]),\n",
       " 'split3_test_score': array([0.83908046, 0.83333333, 0.85632184, 0.85057471, 0.85632184,\n",
       "        0.85057471, 0.85632184, 0.85057471, 0.85632184, 0.85057471]),\n",
       " 'split4_test_score': array([0.85057471, 0.88505747, 0.82183908, 0.86206897, 0.81609195,\n",
       "        0.86206897, 0.81609195, 0.86206897, 0.81609195, 0.86206897]),\n",
       " 'mean_test_score': array([0.8359803 , 0.82227258, 0.81996716, 0.82453859, 0.81881773,\n",
       "        0.82453859, 0.81881773, 0.82453859, 0.81881773, 0.82453859]),\n",
       " 'std_test_score': array([0.0224724 , 0.03746969, 0.02062867, 0.03591843, 0.02065244,\n",
       "        0.03591843, 0.02065244, 0.03591843, 0.02065244, 0.03591843]),\n",
       " 'rank_test_score': array([1, 6, 7, 2, 8, 2, 8, 2, 8, 2], dtype=int32)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)\n",
    "clf.cv_results_\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "275420ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72eb9922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.835980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.822273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.819967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.824539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.818818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.824539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.818818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.824539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.818818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.824539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0       1       linear         0.835980\n",
       "1       1          rbf         0.822273\n",
       "2       4       linear         0.819967\n",
       "3       4          rbf         0.824539\n",
       "4       8       linear         0.818818\n",
       "5       8          rbf         0.824539\n",
       "6      16       linear         0.818818\n",
       "7      16          rbf         0.824539\n",
       "8      32       linear         0.818818\n",
       "9      32          rbf         0.824539"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "194ba06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a6ca8",
   "metadata": {},
   "source": [
    "## Save Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec37d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open ('./sklearn-master/models/sentiment_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44bbaf7",
   "metadata": {},
   "source": [
    "## Load Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6967cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./sklearn-master/models/sentiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7555caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This odd and pretentious novel is based on the true case of an innocent man who falsely confessed to a series of homicides. The nation is on edge in the wake of a series of mysterious disappearances. The targets, all older, solitary sorts, vanish and their presumed abductor leaves nary a clue but for a marked playing card. Oda Sotatsu is a young man living a life both unfulfilling and uninteresting. That is until he meets a troublesome couple, the supposedly charismatic Sato Kakuzo and his girlfriend, the alluring,Jito Joo. Clearly disturbed, they play games and place wagers where the loser has to physically harm himself. They attach to Oda, inducing him into  a wager after plying him with alcohol. After losing the game, he signs a detailed confession admitting culpability in the disappearances. Joo delivers the confession to the police and Oda is soon arrested, imprisoned, abused, tried and convicted. He is subsequently sentenced to death by hanging and executed, remaining silent throughout the whole ordeal. Enter journalist Bell who is drawn to the mystery while still pondering the dissolution of his marriage. The book is largely a series of transcripts of the bewildered and dismayed family members, interrogations, newspaper coverage of the trial and finally with Joo and Kakuzo.This book felt half baked.  The transcript style of telling the story contributed to the unfinished feel. The story lacked suspense and mystery but it was far from a searing condemnation of the Japanese justice system. Obviously a confession is the gold standard in Japanese jurisprudence because there was really no evidence that a crime was committed, much less that Oda committed one. Oda's behavior and refusal to speak or defend himself was inexplicable, even if one factors in traditional concepts of honor. Joo and Kakuzo fail to trigger the fascination that classically destructive couples do. They are not Sid and Nancy, Bonnie and Clyde or even Romeo and Juliet. They are boring and shallow. The ending is a total disappointment making the sacrifice and I use the term loosely of Oda's life stupid and meaningless.This could have been an examination of false confessions or an indictment of the death penalty. It could have been a haunting character study that addressed  the relevance of honor in modern society. The spare writing contributed to a dream like atmosphere but muted even the horror of the gallows. Oda remained a cipher. Despite the cool cover, this book was no more than two hundred plus pages of self indulgence. Pass.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[10])\n",
    "\n",
    "loaded_clf.predict(test_x_vectors[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4485c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
